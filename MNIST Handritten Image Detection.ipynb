{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Image Detection with Keras using MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the data, shuffled and split between train and test sets (x_train and y_rain)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 138,\n",
       "        170, 253, 201, 244, 212, 222, 138,  86,  22,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  95, 253, 252,\n",
       "        252, 252, 252, 253, 252, 252, 252, 252, 245,  80,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 246, 205,  69,\n",
       "         69,  69,  69,  69,  69,  69,  69, 205, 253, 240,  50,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 187, 252, 218,  34,\n",
       "          0,   0,   0,   0,   0,   0,   0, 116, 253, 252,  69,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 248, 252, 253,  92,\n",
       "          0,   0,   0,   0,   0,   0,  95, 230, 253, 157,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 249, 253, 189,  42,\n",
       "          0,   0,   0,   0,  36, 170, 253, 243, 158,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 252, 245, 140,\n",
       "         34,   0,   0,  57, 219, 252, 235,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 205, 253, 252,\n",
       "        234, 184, 184, 253, 240, 100,  44,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 161, 219,\n",
       "        252, 252, 252, 234,  37,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 203,\n",
       "        252, 252, 252, 251, 135,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  76, 255, 253,\n",
       "        205, 168, 220, 255, 253, 137,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 114, 252, 249, 132,\n",
       "         25,   0,   0, 180, 252, 252,  45,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 220, 252, 199,   0,\n",
       "          0,   0,   0,  38, 186, 252, 154,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,  21,   0,\n",
       "          0,   0,   0,   0,  67, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 200,   0,   0,\n",
       "          0,   0,   0,   0,  47, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 185, 253, 201,   0,   0,\n",
       "          0,   0,   0,   3, 118, 253, 245,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,   0,   0,\n",
       "          0,   0,   0,  97, 252, 252,  87,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 240, 252, 123,  70,\n",
       "         70, 112, 184, 222, 252, 170,  13,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 165, 252, 253, 252,\n",
       "        252, 252, 252, 245, 139,  13,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  75, 253, 252,\n",
       "        221, 137, 137,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[333]  ## Just a 28 x 28 numpy array of ints from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the corresponding label in the training set?\n",
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249c86d12b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[333], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) train samples\n",
      "(10000, 28, 28) test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For our purposes, these images are just a vector of 784 inputs, so let's convert\n",
    "x_train = x_train.reshape(len(x_train), 28*28)\n",
    "x_test = x_test.reshape(len(x_test), 28*28)\n",
    "## Keras works with floats, so we must cast the numbers to floats\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "## Normalize the inputs so they are between 0 and 1\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[333]  # now the digit k is represented by a 1 in the kth entry (0-indexed) of the length 10 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will build a model with two hidden layers of size 512\n",
    "# Fully connected inputs at each layer\n",
    "# We will use dropout of .2 to help regularize\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(10, activation='softmax'))   #o/p layer for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Note that this model has a LOT of parameters\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compile the model\n",
    "learning_rate = .001\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "# `categorical cross entropy` is the natural generalization \n",
    "# of the loss function we had in binary classification case, to multi class case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5085 - accuracy: 0.8494 - val_loss: 0.2022 - val_accuracy: 0.9389\n",
      "Epoch 2/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.2525 - accuracy: 0.9273 - val_loss: 0.1527 - val_accuracy: 0.9540\n",
      "Epoch 3/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.2007 - accuracy: 0.9412 - val_loss: 0.1286 - val_accuracy: 0.9608\n",
      "Epoch 4/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1736 - accuracy: 0.9494 - val_loss: 0.1151 - val_accuracy: 0.9661\n",
      "Epoch 5/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1549 - accuracy: 0.9541 - val_loss: 0.1101 - val_accuracy: 0.9659\n",
      "Epoch 6/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1450 - accuracy: 0.9568 - val_loss: 0.1083 - val_accuracy: 0.9683\n",
      "Epoch 7/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1336 - accuracy: 0.9606 - val_loss: 0.1028 - val_accuracy: 0.9696\n",
      "Epoch 8/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1276 - accuracy: 0.9617 - val_loss: 0.0986 - val_accuracy: 0.9703\n",
      "Epoch 9/30\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.1212 - accuracy: 0.9645 - val_loss: 0.0997 - val_accuracy: 0.9716\n",
      "Epoch 10/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1154 - accuracy: 0.9672 - val_loss: 0.0942 - val_accuracy: 0.9711\n",
      "Epoch 11/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1096 - accuracy: 0.9675 - val_loss: 0.0952 - val_accuracy: 0.9727\n",
      "Epoch 12/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1075 - accuracy: 0.9686 - val_loss: 0.1013 - val_accuracy: 0.9722\n",
      "Epoch 13/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1061 - accuracy: 0.9687 - val_loss: 0.0952 - val_accuracy: 0.9756\n",
      "Epoch 14/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1012 - accuracy: 0.9702 - val_loss: 0.0987 - val_accuracy: 0.9733\n",
      "Epoch 15/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0980 - accuracy: 0.9714 - val_loss: 0.0946 - val_accuracy: 0.9742\n",
      "Epoch 16/30\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0974 - accuracy: 0.9715 - val_loss: 0.0926 - val_accuracy: 0.9739\n",
      "Epoch 17/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0970 - accuracy: 0.9714 - val_loss: 0.0921 - val_accuracy: 0.9752\n",
      "Epoch 18/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0942 - accuracy: 0.9732 - val_loss: 0.0997 - val_accuracy: 0.9741\n",
      "Epoch 19/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0941 - accuracy: 0.9727 - val_loss: 0.0946 - val_accuracy: 0.9760\n",
      "Epoch 20/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0890 - accuracy: 0.9735 - val_loss: 0.0952 - val_accuracy: 0.9763\n",
      "Epoch 21/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0903 - accuracy: 0.9738 - val_loss: 0.0978 - val_accuracy: 0.9757\n",
      "Epoch 22/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0888 - accuracy: 0.9743 - val_loss: 0.0994 - val_accuracy: 0.9751\n",
      "Epoch 23/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0893 - accuracy: 0.9743 - val_loss: 0.0965 - val_accuracy: 0.9758\n",
      "Epoch 24/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.0928 - val_accuracy: 0.9769\n",
      "Epoch 25/30\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0854 - accuracy: 0.9753 - val_loss: 0.0958 - val_accuracy: 0.9762\n",
      "Epoch 26/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0832 - accuracy: 0.9756 - val_loss: 0.1079 - val_accuracy: 0.9737\n",
      "Epoch 27/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0823 - accuracy: 0.9758 - val_loss: 0.1038 - val_accuracy: 0.9760\n",
      "Epoch 28/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0786 - accuracy: 0.9772 - val_loss: 0.0992 - val_accuracy: 0.9771\n",
      "Epoch 29/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0827 - accuracy: 0.9767 - val_loss: 0.1000 - val_accuracy: 0.9768\n",
      "Epoch 30/30\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0805 - accuracy: 0.9771 - val_loss: 0.1008 - val_accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128  # mini-batch with 128 examples\n",
    "epochs = 30\n",
    "history = model_1.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10078272968530655\n",
      "Test accuracy: 0.9775999784469604\n"
     ]
    }
   ],
   "source": [
    "## We will use Keras evaluate function to evaluate performance on the test set\n",
    "\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
