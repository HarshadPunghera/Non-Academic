{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('datasets_14370_19291_pima-indians-diabetes.csv', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>times_pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_pressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin_thickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree_function</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times_pregnant  glucose_tolerance_test  \\\n",
       "times_pregnant                1.000000                0.129459   \n",
       "glucose_tolerance_test        0.129459                1.000000   \n",
       "blood_pressure                0.141282                0.152590   \n",
       "skin_thickness               -0.081672                0.057328   \n",
       "insulin                      -0.073535                0.331357   \n",
       "bmi                           0.017683                0.221071   \n",
       "pedigree_function            -0.033523                0.137337   \n",
       "age                           0.544341                0.263514   \n",
       "has_diabetes                  0.221898                0.466581   \n",
       "\n",
       "                        blood_pressure  skin_thickness   insulin       bmi  \\\n",
       "times_pregnant                0.141282       -0.081672 -0.073535  0.017683   \n",
       "glucose_tolerance_test        0.152590        0.057328  0.331357  0.221071   \n",
       "blood_pressure                1.000000        0.207371  0.088933  0.281805   \n",
       "skin_thickness                0.207371        1.000000  0.436783  0.392573   \n",
       "insulin                       0.088933        0.436783  1.000000  0.197859   \n",
       "bmi                           0.281805        0.392573  0.197859  1.000000   \n",
       "pedigree_function             0.041265        0.183928  0.185071  0.140647   \n",
       "age                           0.239528       -0.113970 -0.042163  0.036242   \n",
       "has_diabetes                  0.065068        0.074752  0.130548  0.292695   \n",
       "\n",
       "                        pedigree_function       age  has_diabetes  \n",
       "times_pregnant                  -0.033523  0.544341      0.221898  \n",
       "glucose_tolerance_test           0.137337  0.263514      0.466581  \n",
       "blood_pressure                   0.041265  0.239528      0.065068  \n",
       "skin_thickness                   0.183928 -0.113970      0.074752  \n",
       "insulin                          0.185071 -0.042163      0.130548  \n",
       "bmi                              0.140647  0.036242      0.292695  \n",
       "pedigree_function                1.000000  0.033561      0.173844  \n",
       "age                              0.033561  1.000000      0.238356  \n",
       "has_diabetes                     0.173844  0.238356      1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>74</td>\n",
       "      <td>25</td>\n",
       "      <td>293</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.385</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.944</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>325</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.583</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.239</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "364               4                     147              74              25   \n",
       "581               6                     109              60              27   \n",
       "396               3                      96              56              34   \n",
       "360               5                     189              64              33   \n",
       "387               8                     105             100              36   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "364      293  34.9              0.385   30             0  \n",
       "581        0  25.0              0.206   27             0  \n",
       "396      115  24.7              0.944   39             0  \n",
       "360      325  31.2              0.583   29             1  \n",
       "387        0  43.3              0.239   45             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.6822 - accuracy: 0.5972 - val_loss: 0.6805 - val_accuracy: 0.5885\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.6024 - val_loss: 0.6750 - val_accuracy: 0.5990\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.6094 - val_loss: 0.6697 - val_accuracy: 0.6042\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6643 - accuracy: 0.6128 - val_loss: 0.6647 - val_accuracy: 0.6042\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6588 - accuracy: 0.6285 - val_loss: 0.6598 - val_accuracy: 0.6198\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6535 - accuracy: 0.6372 - val_loss: 0.6552 - val_accuracy: 0.6302\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6484 - accuracy: 0.6406 - val_loss: 0.6507 - val_accuracy: 0.6302\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6435 - accuracy: 0.6476 - val_loss: 0.6464 - val_accuracy: 0.6354\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.6493 - val_loss: 0.6422 - val_accuracy: 0.6302\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.6580 - val_loss: 0.6383 - val_accuracy: 0.6354\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.6615 - val_loss: 0.6344 - val_accuracy: 0.6354\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.6736 - val_loss: 0.6307 - val_accuracy: 0.6458\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6217 - accuracy: 0.6771 - val_loss: 0.6272 - val_accuracy: 0.6510\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.6875 - val_loss: 0.6238 - val_accuracy: 0.6510\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6139 - accuracy: 0.6892 - val_loss: 0.6205 - val_accuracy: 0.6458\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6103 - accuracy: 0.6910 - val_loss: 0.6172 - val_accuracy: 0.6562\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6067 - accuracy: 0.6979 - val_loss: 0.6141 - val_accuracy: 0.6510\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6032 - accuracy: 0.7031 - val_loss: 0.6111 - val_accuracy: 0.6510\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5998 - accuracy: 0.7049 - val_loss: 0.6081 - val_accuracy: 0.6458\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5966 - accuracy: 0.7031 - val_loss: 0.6052 - val_accuracy: 0.6510\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.7066 - val_loss: 0.6025 - val_accuracy: 0.6562\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.7083 - val_loss: 0.5998 - val_accuracy: 0.6562\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5873 - accuracy: 0.7031 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5844 - accuracy: 0.7049 - val_loss: 0.5947 - val_accuracy: 0.6771\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5816 - accuracy: 0.7031 - val_loss: 0.5922 - val_accuracy: 0.6771\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5789 - accuracy: 0.7083 - val_loss: 0.5898 - val_accuracy: 0.6875\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5762 - accuracy: 0.7135 - val_loss: 0.5875 - val_accuracy: 0.6875\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.7188 - val_loss: 0.5853 - val_accuracy: 0.6927\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5712 - accuracy: 0.7205 - val_loss: 0.5831 - val_accuracy: 0.6979\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.7222 - val_loss: 0.5810 - val_accuracy: 0.6979\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.7240 - val_loss: 0.5790 - val_accuracy: 0.6979\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5641 - accuracy: 0.7240 - val_loss: 0.5770 - val_accuracy: 0.7031\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5619 - accuracy: 0.7274 - val_loss: 0.5751 - val_accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.7309 - val_loss: 0.5732 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.7326 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.7344 - val_loss: 0.5697 - val_accuracy: 0.7135\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7378 - val_loss: 0.5680 - val_accuracy: 0.7135\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5513 - accuracy: 0.7378 - val_loss: 0.5663 - val_accuracy: 0.7135\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7396 - val_loss: 0.5647 - val_accuracy: 0.7344\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.7396 - val_loss: 0.5632 - val_accuracy: 0.7344\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5456 - accuracy: 0.7396 - val_loss: 0.5617 - val_accuracy: 0.7344\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7413 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7431 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5402 - accuracy: 0.7413 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7396 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7413 - val_loss: 0.5547 - val_accuracy: 0.7292\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5353 - accuracy: 0.7413 - val_loss: 0.5535 - val_accuracy: 0.7292\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7413 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.7413 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.7413 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5292 - accuracy: 0.7431 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.7448 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.7431 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.7448 - val_loss: 0.5456 - val_accuracy: 0.7344\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5237 - accuracy: 0.7431 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.7431 - val_loss: 0.5436 - val_accuracy: 0.7344\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7431 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7431 - val_loss: 0.5417 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.7431 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7483 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.7500 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5149 - accuracy: 0.7500 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5137 - accuracy: 0.7483 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.7483 - val_loss: 0.5365 - val_accuracy: 0.7344\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5115 - accuracy: 0.7483 - val_loss: 0.5356 - val_accuracy: 0.7344\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.7517 - val_loss: 0.5348 - val_accuracy: 0.7344\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.7517 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5083 - accuracy: 0.7517 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.7552 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.7552 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.7569 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5042 - accuracy: 0.7569 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.7587 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5023 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5014 - accuracy: 0.7604 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.7604 - val_loss: 0.5277 - val_accuracy: 0.7344\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.7604 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.7604 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4969 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.7622 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4945 - accuracy: 0.7622 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.7622 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4921 - accuracy: 0.7656 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.7656 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4883 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.7708 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.7708 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4842 - accuracy: 0.7708 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.7726 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.7743 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.7760 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.77 - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(GD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-52856171b604>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41535407],\n",
       "       [0.6633033 ],\n",
       "       [0.3244111 ],\n",
       "       [0.21368268],\n",
       "       [0.1987974 ],\n",
       "       [0.4981894 ],\n",
       "       [0.08118996],\n",
       "       [0.31475806],\n",
       "       [0.86975056],\n",
       "       [0.17624307]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.813\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f9995bbcc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4501 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.78 - 0s 9ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4328 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4328 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.77 - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4325 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.7760 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7760 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4281 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.77 - 0s 9ms/step - loss: 0.4261 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7812 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7812 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7812 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7812 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7812 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7812 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7830 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7812 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7847 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.7847 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4231 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4221 - accuracy: 0.7882 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5131 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.79 - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7934 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.80 - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5169 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5173 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f99a895518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
